{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Stacked Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 생성\n",
    "# ont_hot = True는 Y의 레이블이 1이라면 [0,1,0,0,0,0,0,0,0,0] 처럼 0또는 1로 코딩해주는것\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net 파라미터 설정\n",
    "num_hidden_1 = 256 # 첫번째 레이어 개수\n",
    "num_hidden_2 = 128 # 두번째 레이어 개수\n",
    "num_input = 784 # MNIST (shape: 28*28)\n",
    "X = tf.placeholder(\"float\", [None, num_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_normal\n",
    "- 평균이 0이고 표준편차가 1인 정규분포에서의 난수발생\n",
    "- weights : 가중치 함수 정의\n",
    "- bias : bias 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def bias(shape):\n",
    "    return tf.Variable(tf.random_normal(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- encoder : layer가 2개인 encoder layer 함수 정의\n",
    "- decoder : layer가 2개인 decoder layer 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(x, weights([num_input, num_hidden_1])) + bias([num_hidden_1]))\n",
    "    layer2 = tf.nn.sigmoid(tf.matmul(layer1, weights([num_hidden_1, num_hidden_2])) + bias([num_hidden_2]))\n",
    "    return layer2\n",
    "    \n",
    "def decoder(x):\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(x, weights([num_hidden_2, num_hidden_1])) + bias([num_hidden_1]))\n",
    "    layer2 = tf.nn.sigmoid(tf.matmul(layer1, weights([num_hidden_1, num_input])) + bias([num_input]))\n",
    "    return layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter 및 Layer 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파라미터 설정\n",
    "learning_rate = 0.01\n",
    "num_steps = 30000\n",
    "batch_size = 256\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# loss(cost) 함수를 만들기 위한 데이터 처리\n",
    "# Prediction(decoder까지 통과한 variable을 predictor로 설정)\n",
    "y_pred = decoder_op\n",
    "# Target 데이터는 input(Image)로 설정\n",
    "y_true = X\n",
    "\n",
    "# loss(cost)는 MSE, optimizer는 RMSProp\n",
    "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본 학습 Parameter 설정\n",
    "- autoencoder는 비지도 학습이기 때문에 loss를 계산할 때 실제 x값을 target으로 설정하고 decoder를 통과한 재 구조화된 output을 예측값으로 보고 계산함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100, minibatch loss 0.181202\n",
      "step 200, minibatch loss 0.0698748\n",
      "step 300, minibatch loss 0.0644743\n",
      "step 400, minibatch loss 0.0597383\n",
      "step 500, minibatch loss 0.0570955\n",
      "step 600, minibatch loss 0.0494706\n",
      "step 700, minibatch loss 0.0457393\n",
      "step 800, minibatch loss 0.0393451\n",
      "step 900, minibatch loss 0.0362758\n",
      "step 1000, minibatch loss 0.0338071\n",
      "step 1100, minibatch loss 0.0328956\n",
      "step 1200, minibatch loss 0.0296682\n",
      "step 1300, minibatch loss 0.0309009\n",
      "step 1400, minibatch loss 0.0271609\n",
      "step 1500, minibatch loss 0.0230386\n",
      "step 1600, minibatch loss 0.0240576\n",
      "step 1700, minibatch loss 0.0225331\n",
      "step 1800, minibatch loss 0.0207874\n",
      "step 1900, minibatch loss 0.0207319\n",
      "step 2000, minibatch loss 0.0202817\n",
      "step 2100, minibatch loss 0.0196594\n",
      "step 2200, minibatch loss 0.0186865\n",
      "step 2300, minibatch loss 0.0176326\n",
      "step 2400, minibatch loss 0.0165321\n",
      "step 2500, minibatch loss 0.0184132\n",
      "step 2600, minibatch loss 0.0170798\n",
      "step 2700, minibatch loss 0.0165203\n",
      "step 2800, minibatch loss 0.0162327\n",
      "step 2900, minibatch loss 0.0157954\n",
      "step 3000, minibatch loss 0.0142978\n",
      "step 3100, minibatch loss 0.0141968\n",
      "step 3200, minibatch loss 0.0154663\n",
      "step 3300, minibatch loss 0.0142405\n",
      "step 3400, minibatch loss 0.0143164\n",
      "step 3500, minibatch loss 0.0135361\n",
      "step 3600, minibatch loss 0.0127352\n",
      "step 3700, minibatch loss 0.0127459\n",
      "step 3800, minibatch loss 0.012802\n",
      "step 3900, minibatch loss 0.0126087\n",
      "step 4000, minibatch loss 0.0120916\n",
      "step 4100, minibatch loss 0.0124579\n",
      "step 4200, minibatch loss 0.0120318\n",
      "step 4300, minibatch loss 0.0111059\n",
      "step 4400, minibatch loss 0.0119109\n",
      "step 4500, minibatch loss 0.011983\n",
      "step 4600, minibatch loss 0.0120608\n",
      "step 4700, minibatch loss 0.0107546\n",
      "step 4800, minibatch loss 0.0106521\n",
      "step 4900, minibatch loss 0.0114628\n",
      "step 5000, minibatch loss 0.0111358\n",
      "step 5100, minibatch loss 0.011368\n",
      "step 5200, minibatch loss 0.00987263\n",
      "step 5300, minibatch loss 0.0106103\n",
      "step 5400, minibatch loss 0.0107394\n",
      "step 5500, minibatch loss 0.0104794\n",
      "step 5600, minibatch loss 0.0104759\n",
      "step 5700, minibatch loss 0.0104934\n",
      "step 5800, minibatch loss 0.0100398\n",
      "step 5900, minibatch loss 0.00979937\n",
      "step 6000, minibatch loss 0.0107409\n",
      "step 6100, minibatch loss 0.0103532\n",
      "step 6200, minibatch loss 0.00914198\n",
      "step 6300, minibatch loss 0.00986328\n",
      "step 6400, minibatch loss 0.00962208\n",
      "step 6500, minibatch loss 0.00975791\n",
      "step 6600, minibatch loss 0.00959541\n",
      "step 6700, minibatch loss 0.0108119\n",
      "step 6800, minibatch loss 0.00936853\n",
      "step 6900, minibatch loss 0.00935885\n",
      "step 7000, minibatch loss 0.00953438\n",
      "step 7100, minibatch loss 0.00972318\n",
      "step 7200, minibatch loss 0.00981772\n",
      "step 7300, minibatch loss 0.0101197\n",
      "step 7400, minibatch loss 0.00982365\n",
      "step 7500, minibatch loss 0.00979521\n",
      "step 7600, minibatch loss 0.00831299\n",
      "step 7700, minibatch loss 0.00930034\n",
      "step 7800, minibatch loss 0.00963693\n",
      "step 7900, minibatch loss 0.00868212\n",
      "step 8000, minibatch loss 0.00910863\n",
      "step 8100, minibatch loss 0.00883222\n",
      "step 8200, minibatch loss 0.00875171\n",
      "step 8300, minibatch loss 0.00908616\n",
      "step 8400, minibatch loss 0.00950268\n",
      "step 8500, minibatch loss 0.00914483\n",
      "step 8600, minibatch loss 0.00871177\n",
      "step 8700, minibatch loss 0.00877213\n",
      "step 8800, minibatch loss 0.00875208\n",
      "step 8900, minibatch loss 0.00859118\n",
      "step 9000, minibatch loss 0.00793038\n",
      "step 9100, minibatch loss 0.00853776\n",
      "step 9200, minibatch loss 0.00861154\n",
      "step 9300, minibatch loss 0.00756079\n",
      "step 9400, minibatch loss 0.00868756\n",
      "step 9500, minibatch loss 0.00840406\n",
      "step 9600, minibatch loss 0.00817082\n",
      "step 9700, minibatch loss 0.00821393\n",
      "step 9800, minibatch loss 0.00838331\n",
      "step 9900, minibatch loss 0.0079652\n",
      "step 10000, minibatch loss 0.00764611\n",
      "step 10100, minibatch loss 0.00828368\n",
      "step 10200, minibatch loss 0.00809039\n",
      "step 10300, minibatch loss 0.00793589\n",
      "step 10400, minibatch loss 0.00800038\n",
      "step 10500, minibatch loss 0.00784381\n",
      "step 10600, minibatch loss 0.00763201\n",
      "step 10700, minibatch loss 0.00798625\n",
      "step 10800, minibatch loss 0.00739815\n",
      "step 10900, minibatch loss 0.00786244\n",
      "step 11000, minibatch loss 0.00779131\n",
      "step 11100, minibatch loss 0.00744964\n",
      "step 11200, minibatch loss 0.00788936\n",
      "step 11300, minibatch loss 0.00798575\n",
      "step 11400, minibatch loss 0.00756517\n",
      "step 11500, minibatch loss 0.00826513\n",
      "step 11600, minibatch loss 0.00787499\n",
      "step 11700, minibatch loss 0.00749573\n",
      "step 11800, minibatch loss 0.00759632\n",
      "step 11900, minibatch loss 0.00802319\n",
      "step 12000, minibatch loss 0.00719681\n",
      "step 12100, minibatch loss 0.00769783\n",
      "step 12200, minibatch loss 0.00775343\n",
      "step 12300, minibatch loss 0.00720303\n",
      "step 12400, minibatch loss 0.00751809\n",
      "step 12500, minibatch loss 0.0075136\n",
      "step 12600, minibatch loss 0.00814298\n",
      "step 12700, minibatch loss 0.00723302\n",
      "step 12800, minibatch loss 0.00776349\n",
      "step 12900, minibatch loss 0.00712803\n",
      "step 13000, minibatch loss 0.00749501\n",
      "step 13100, minibatch loss 0.00732948\n",
      "step 13200, minibatch loss 0.00688109\n",
      "step 13300, minibatch loss 0.00822286\n",
      "step 13400, minibatch loss 0.00714281\n",
      "step 13500, minibatch loss 0.00691467\n",
      "step 13600, minibatch loss 0.00709418\n",
      "step 13700, minibatch loss 0.00807047\n",
      "step 13800, minibatch loss 0.00696596\n",
      "step 13900, minibatch loss 0.00727576\n",
      "step 14000, minibatch loss 0.00701011\n",
      "step 14100, minibatch loss 0.00730924\n",
      "step 14200, minibatch loss 0.00649935\n",
      "step 14300, minibatch loss 0.00638673\n",
      "step 14400, minibatch loss 0.00682412\n",
      "step 14500, minibatch loss 0.00678388\n",
      "step 14600, minibatch loss 0.00799664\n",
      "step 14700, minibatch loss 0.00711302\n",
      "step 14800, minibatch loss 0.00717589\n",
      "step 14900, minibatch loss 0.00709972\n",
      "step 15000, minibatch loss 0.007015\n",
      "step 15100, minibatch loss 0.00641573\n",
      "step 15200, minibatch loss 0.00725884\n",
      "step 15300, minibatch loss 0.00683217\n",
      "step 15400, minibatch loss 0.00681311\n",
      "step 15500, minibatch loss 0.00699968\n",
      "step 15600, minibatch loss 0.00695889\n",
      "step 15700, minibatch loss 0.0072492\n",
      "step 15800, minibatch loss 0.00650388\n",
      "step 15900, minibatch loss 0.00674046\n",
      "step 16000, minibatch loss 0.00740143\n",
      "step 16100, minibatch loss 0.00723176\n",
      "step 16200, minibatch loss 0.00635871\n",
      "step 16300, minibatch loss 0.00690158\n",
      "step 16400, minibatch loss 0.00659439\n",
      "step 16500, minibatch loss 0.00654145\n",
      "step 16600, minibatch loss 0.006114\n",
      "step 16700, minibatch loss 0.00671855\n",
      "step 16800, minibatch loss 0.00659826\n",
      "step 16900, minibatch loss 0.00749734\n",
      "step 17000, minibatch loss 0.0065033\n",
      "step 17100, minibatch loss 0.0072195\n",
      "step 17200, minibatch loss 0.00580065\n",
      "step 17300, minibatch loss 0.00662779\n",
      "step 17400, minibatch loss 0.00645141\n",
      "step 17500, minibatch loss 0.00712438\n",
      "step 17600, minibatch loss 0.00710201\n",
      "step 17700, minibatch loss 0.00685415\n",
      "step 17800, minibatch loss 0.00632486\n",
      "step 17900, minibatch loss 0.00669192\n",
      "step 18000, minibatch loss 0.00729078\n",
      "step 18100, minibatch loss 0.00684783\n",
      "step 18200, minibatch loss 0.00687991\n",
      "step 18300, minibatch loss 0.00619044\n",
      "step 18400, minibatch loss 0.0060692\n",
      "step 18500, minibatch loss 0.00654337\n",
      "step 18600, minibatch loss 0.00645763\n",
      "step 18700, minibatch loss 0.00659034\n",
      "step 18800, minibatch loss 0.00613264\n",
      "step 18900, minibatch loss 0.00632239\n",
      "step 19000, minibatch loss 0.00690946\n",
      "step 19100, minibatch loss 0.00608673\n",
      "step 19200, minibatch loss 0.00671745\n",
      "step 19300, minibatch loss 0.0065061\n",
      "step 19400, minibatch loss 0.00594398\n",
      "step 19500, minibatch loss 0.00621087\n",
      "step 19600, minibatch loss 0.00648397\n",
      "step 19700, minibatch loss 0.00628936\n",
      "step 19800, minibatch loss 0.00642553\n",
      "step 19900, minibatch loss 0.00638052\n",
      "step 20000, minibatch loss 0.0062086\n",
      "step 20100, minibatch loss 0.00676732\n",
      "step 20200, minibatch loss 0.00642047\n",
      "step 20300, minibatch loss 0.00632869\n",
      "step 20400, minibatch loss 0.00603377\n",
      "step 20500, minibatch loss 0.00616102\n",
      "step 20600, minibatch loss 0.00603917\n",
      "step 20700, minibatch loss 0.00578418\n",
      "step 20800, minibatch loss 0.00686771\n",
      "step 20900, minibatch loss 0.00630055\n",
      "step 21000, minibatch loss 0.00582323\n",
      "step 21100, minibatch loss 0.00600448\n",
      "step 21200, minibatch loss 0.00610339\n",
      "step 21300, minibatch loss 0.0056526\n",
      "step 21400, minibatch loss 0.00619621\n",
      "step 21500, minibatch loss 0.00563685\n",
      "step 21600, minibatch loss 0.00559128\n",
      "step 21700, minibatch loss 0.00591709\n",
      "step 21800, minibatch loss 0.00585378\n",
      "step 21900, minibatch loss 0.00603115\n",
      "step 22000, minibatch loss 0.00665035\n",
      "step 22100, minibatch loss 0.00588125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22200, minibatch loss 0.00613094\n",
      "step 22300, minibatch loss 0.00591056\n",
      "step 22400, minibatch loss 0.00584875\n",
      "step 22500, minibatch loss 0.00560882\n",
      "step 22600, minibatch loss 0.00561069\n",
      "step 22700, minibatch loss 0.00551754\n",
      "step 22800, minibatch loss 0.00547412\n",
      "step 22900, minibatch loss 0.00592802\n",
      "step 23000, minibatch loss 0.00631865\n",
      "step 23100, minibatch loss 0.00608463\n",
      "step 23200, minibatch loss 0.00562245\n",
      "step 23300, minibatch loss 0.00612467\n",
      "step 23400, minibatch loss 0.00631963\n",
      "step 23500, minibatch loss 0.00579416\n",
      "step 23600, minibatch loss 0.00547785\n",
      "step 23700, minibatch loss 0.00591241\n",
      "step 23800, minibatch loss 0.00605042\n",
      "step 23900, minibatch loss 0.00634819\n",
      "step 24000, minibatch loss 0.00564406\n",
      "step 24100, minibatch loss 0.00585833\n",
      "step 24200, minibatch loss 0.00635875\n",
      "step 24300, minibatch loss 0.00578867\n",
      "step 24400, minibatch loss 0.00603885\n",
      "step 24500, minibatch loss 0.00574126\n",
      "step 24600, minibatch loss 0.00484831\n",
      "step 24700, minibatch loss 0.00575313\n",
      "step 24800, minibatch loss 0.00562895\n",
      "step 24900, minibatch loss 0.00599649\n",
      "step 25000, minibatch loss 0.00592957\n",
      "step 25100, minibatch loss 0.00562392\n",
      "step 25200, minibatch loss 0.00580463\n",
      "step 25300, minibatch loss 0.00639745\n",
      "step 25400, minibatch loss 0.0053415\n",
      "step 25500, minibatch loss 0.00586773\n",
      "step 25600, minibatch loss 0.00512916\n",
      "step 25700, minibatch loss 0.00577503\n",
      "step 25800, minibatch loss 0.00640187\n",
      "step 25900, minibatch loss 0.00596447\n",
      "step 26000, minibatch loss 0.00534869\n",
      "step 26100, minibatch loss 0.00499462\n",
      "step 26200, minibatch loss 0.00593632\n",
      "step 26300, minibatch loss 0.00546124\n",
      "step 26400, minibatch loss 0.00538066\n",
      "step 26500, minibatch loss 0.00577664\n",
      "step 26600, minibatch loss 0.00622066\n",
      "step 26700, minibatch loss 0.00580361\n",
      "step 26800, minibatch loss 0.00561117\n",
      "step 26900, minibatch loss 0.00568486\n",
      "step 27000, minibatch loss 0.00574357\n",
      "step 27100, minibatch loss 0.00550398\n",
      "step 27200, minibatch loss 0.00536137\n",
      "step 27300, minibatch loss 0.00609462\n",
      "step 27400, minibatch loss 0.00597986\n",
      "step 27500, minibatch loss 0.00593637\n",
      "step 27600, minibatch loss 0.00530104\n",
      "step 27700, minibatch loss 0.00555481\n",
      "step 27800, minibatch loss 0.00546919\n",
      "step 27900, minibatch loss 0.00629877\n",
      "step 28000, minibatch loss 0.00494278\n",
      "step 28100, minibatch loss 0.00518836\n",
      "step 28200, minibatch loss 0.00587912\n",
      "step 28300, minibatch loss 0.00523612\n",
      "step 28400, minibatch loss 0.00548843\n",
      "step 28500, minibatch loss 0.00544336\n",
      "step 28600, minibatch loss 0.00546455\n",
      "step 28700, minibatch loss 0.00561826\n",
      "step 28800, minibatch loss 0.00545339\n",
      "step 28900, minibatch loss 0.00538509\n",
      "step 29000, minibatch loss 0.00489362\n",
      "step 29100, minibatch loss 0.00537983\n",
      "step 29200, minibatch loss 0.00563652\n",
      "step 29300, minibatch loss 0.00515477\n",
      "step 29400, minibatch loss 0.00550629\n",
      "step 29500, minibatch loss 0.00592829\n",
      "step 29600, minibatch loss 0.00518948\n",
      "step 29700, minibatch loss 0.00556633\n",
      "step 29800, minibatch loss 0.00558148\n",
      "step 29900, minibatch loss 0.0052229\n",
      "step 30000, minibatch loss 0.00517204\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 모델 Train\n",
    "for i in range(1, num_steps+1):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    #Label은 필요 없기 때문에 image만 feed_dict으로 call\n",
    "    result = sess.run([optimizer, loss], feed_dict={X:batch[0]})\n",
    "    if i%100 == 0:\n",
    "        print(\"step %d, minibatch loss %g\"%(i, result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 횟수가 늘어날수록 loss(cost)가 줄어드는것을 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origi Image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10435358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed Images\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106fa940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test (Encoding and Decoding)\n",
    "n = 3\n",
    "canvas_orig = np.empty((28 * n, 28 * n))\n",
    "canvas_recon = np.empty((28 * n, 28 * n))\n",
    "\n",
    "for i in range(n):\n",
    "    batch,_ = mnist.test.next_batch(n)    # 테스트 데이터\n",
    "    g = sess.run(decoder_op, feed_dict={X: batch})# 테스트 데이터를 학습 한 operator에 적합\n",
    "    for j in range(n):# 원본 이미지 생성\n",
    "        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = batch[j].reshape([28, 28])\n",
    "    for j in range(n): # 재 구조화 된 이미지 생성\n",
    "        canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "print(\"Origi Image\")\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Reconstructed Images\")\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
